{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#environment preparation\n",
        "(~about 20 minutes)"
      ],
      "metadata": {
        "id": "Kah9dWQeczu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title clone git\n",
        "!git clone https://github.com/Nidchapan/Closed-Domain-Chatbot.git\n",
        "!gdown 1Litzuc0kKu52w-yupXqV3zEySc3WA9bU\n",
        "\n",
        "%cd /content/Closed-Domain-Chatbot/\n",
        "!mv intent_classification_weight.hdf5 weight"
      ],
      "metadata": {
        "cellView": "form",
        "id": "aWMsuIkLDBfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title install library\n",
        "!pip install openai\n",
        "!pip install pythainlp[full]\n",
        "!pip install pyngrok\n",
        "!pip install line-bot-sdk\n",
        "\n",
        "!pip install --no-deps thai2transformers==0.1.2\n",
        "!pip install translate\n",
        "!pip install tensorflow_text\n",
        "!pip install -q simpletransformers\n",
        "!pip install numpy requests nlpaug\n",
        "\n",
        "!pip install --q torch sentencepiece accelerate transformers pandas requests gradio bitsandbytes langchain faiss-gpu sentence-transformers gradio\n",
        "!pip3 install tensorflow_text>=2.0.0rc0\n",
        "!pip install keras-nlp\n",
        "!pip install numba\n",
        "!pip install tensorflow-addons"
      ],
      "metadata": {
        "cellView": "form",
        "id": "MwgO6hO9duc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title import library\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from transformers import pipeline\n",
        "\n",
        "import nltk\n",
        "import pythainlp\n",
        "from pythainlp.util import normalize\n",
        "from pythainlp.tokenize import subword_tokenize\n",
        "from pythainlp.corpus import thai_stopwords\n",
        "\n",
        "from flask import Flask, request\n",
        "from pyngrok import ngrok\n",
        "import copy\n",
        "\n",
        "from linebot import  LineBotApi, WebhookHandler\n",
        "from linebot.models import TextMessage, TextSendMessage\n",
        "\n",
        "import openai"
      ],
      "metadata": {
        "cellView": "form",
        "id": "51dJky3Kp7th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OpenAi API\n",
        "You can find your API key at https://platform.openai.com/account/api-keys."
      ],
      "metadata": {
        "id": "qNPVAAU3tsir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = '<openai_api_key_here>'\n",
        "def open_domain(question_txt):\n",
        "    messages = [{\"role\": \"user\", \"content\":question_txt}]\n",
        "    chat = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=messages)\n",
        "    ans_text = chat.choices[0].message.content\n",
        "    return ans_text"
      ],
      "metadata": {
        "id": "DWG4fyS6qZLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "open_domain('สวัสดี')"
      ],
      "metadata": {
        "id": "6W0IFezZyvt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "IaY1P075jqWy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title product-shop information\n",
        "\n",
        "df_product = pd.read_excel('dataset/product.xlsx')\n",
        "shop_information = [\n",
        "\"ร้านเปิด-ปิดเวลา 9:00-20:00 ร้านหยุดทุกวันพุธ\",\n",
        "\"เบอร์ติดต่อร้าน 099-999-9999\",\n",
        "\"ร้านตั้งอยู่ที่ 'เลขที่ 148 ถนนเสรีไทย แขวงคลองจั่น เขตบางกะปิ กรุงเทพฯ 10240'\",\n",
        "\"ร้าน 'THE CLOTHSET' ขายเสื้อผ้าสตรี\",\n",
        "]\n",
        "\n",
        "def product_detail(product_name, shop_prob, shop_th=0.6):\n",
        "    product_size_detail_top = \"\"\"\n",
        "ขนาดเสื้อ คือ\n",
        "ไซส์ S   มีขนาดรอบอก 34 นิ้ว\n",
        "ไซส์ M   มีขนาดรอบอก 36 นิ้ว\n",
        "ไซส์ L   มีขนาดรอบอก 38 นิ้ว\n",
        "ไซส์ XL  มีขนาดรอบอก 40 นิ้ว\n",
        "ไซส์ XXL มีขนาดรอบอก 42 นิ้ว\n",
        "ไซส์ XXL มีขนาดรอบอก 44 นิ้ว\n",
        "\"\"\"\n",
        "    product_size_detail_bottom = \"\"\"\n",
        "ขนาดกางเกงและกระโปรง คือ\n",
        "ไซส์ S   มีขนาดรอบเอว 26 นิ้ว สะโพก 30 นิ้ว\n",
        "ไซส์ M   มีขนาดรอบเอว 30 นิ้ว สะโพก 32 นิ้ว\n",
        "ไซส์ L   มีขนาดรอบเอว 34 นิ้ว สะโพก 36 นิ้ว\n",
        "ไซส์ XL  มีขนาดรอบเอว 33 นิ้ว สะโพก 40 นิ้ว\n",
        "ไซส์ XXL มีขนาดรอบเอว 36 นิ้ว สะโพก 43 นิ้ว\n",
        "\"\"\"\n",
        "    answ = []\n",
        "    count_product = df_product.loc[df_product['product']==product_name,'count'].item()\n",
        "    if count_product == 0:\n",
        "      answ.append('ขออภัยค่ะคุณลูกค้า ตอนนี้สินค้าหมดค่ะ')\n",
        "    else:\n",
        "      if shop_prob.loc[shop_prob['labels']=='size','scores'].item() >= shop_th:\n",
        "        tmp = df_product.loc[df_product['product']==product_name,'size'].item()\n",
        "        if 'เสื้อ' in product_name:\n",
        "          answ.append('มีขนาด '+tmp+product_size_detail_top)\n",
        "        else:\n",
        "          answ.append('มีขนาด '+tmp+product_size_detail_bottom)\n",
        "      if shop_prob.loc[shop_prob['labels']=='cost','scores'].item() >= shop_th:\n",
        "        tmp = df_product.loc[df_product['product']==product_name,'price'].item()\n",
        "        tmp1 = df_product.loc[df_product['product']==product_name,'promotion_type'].item()\n",
        "        tmp2 = df_product.loc[df_product['product']==product_name,'promotion_price'].item()\n",
        "        if tmp1 == '1 get 1':\n",
        "          answ.append('ตอนนี้มีโปรโมชั่นซื้อ 1 แถม 1 ค่ะคุณลูกค้า หากมีข้อสงสัยเพิ่มเติมสามารถสอบถามได้เลยค่ะ')\n",
        "        elif tmp1 == 'discount':\n",
        "          answ.append(f'ตอนนี้มีโปรโมชั่นลดราคาจาก {tmp:d} เหลือเพียง {tmp2:d} บาท หากมีข้อสงสัยเพิ่มเติมสามารถสอบถามได้เลยค่ะ')\n",
        "        answ.append('ราคา '+str(int(tmp))+' บาท')\n",
        "      if shop_prob.loc[shop_prob['labels']=='material','scores'].item() >= shop_th:\n",
        "        tmp = df_product.loc[df_product['product']==product_name,'material'].item()\n",
        "        answ.append('ทำจาก'+tmp)\n",
        "      if shop_prob.loc[shop_prob['labels']=='color','scores'].item() >= shop_th:\n",
        "        tmp = df_product.loc[df_product['product']==product_name,'color'].item()\n",
        "        answ.append('สินค้ามีสี '+tmp)\n",
        "      if shop_prob.loc[shop_prob['labels']=='promotion','scores'].item() >= shop_th:\n",
        "        tmp = \"\"\"ตอนนี้มีโปรโมชั่นซื้อ 1 แถม 1 สำหรับเสื้อครอป\n",
        "โปรโมชั่นลดราคาสำหรับกางเกงขาสั้นจาก 199 เหลือเพียง 149 บาท หากมีข้อสงสัยเพิ่มเติมสามารถสอบถามได้เลยค่ะ\n",
        "        \"\"\"\n",
        "        answ.append(tmp)\n",
        "    answ = '\\n'.join(answ)\n",
        "    if len(re.findall('หากมีข้อสงสัยเพิ่มเติมสามารถสอบถามได้เลยค่ะ',answ))>1:\n",
        "      answ = answ.replace('หากมีข้อสงสัยเพิ่มเติมสามารถสอบถามได้เลยค่ะ','').strip()+' หากมีข้อสงสัยเพิ่มเติมสามารถสอบถามได้เลยค่ะ'\n",
        "    elif (len(re.findall('หากมีข้อสงสัยเพิ่มเติมสามารถสอบถามได้เลยค่ะ',answ))==0) & ('ตอนนี้สินค้าหมดค่ะ' not in answ):\n",
        "      answ = answ+'\\nตอนนี้ยังมีสินค้าอยู่ลูกค้าสนใจรับเลยไหมคะ หรือหากมีข้อสงสัยเพิ่มเติมสามารถสอบถามได้เลยค่ะ'\n",
        "    return answ"
      ],
      "metadata": {
        "cellView": "form",
        "id": "M28ccj2bv4-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title models\n",
        "\n",
        "#intent classification\n",
        "preprocessor = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder-cmlm/multilingual-preprocess/2\", name = 'USE_PREPROCESSOR')\n",
        "encoder = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder-cmlm/multilingual-base/1\", name = 'USE_ENDCODER')\n",
        "\n",
        "label_dict = {0: 'ask_for_info', 1: 'comment', 2: 'greeting', 3: 'order', 4: 'shop_open'}\n",
        "num_class = 5\n",
        "i = tf.keras.layers.Input(shape=(), dtype=tf.string, name='TEXT_INPUT')\n",
        "x = preprocessor(i)\n",
        "x = encoder(x)\n",
        "x = tf.keras.layers.Dropout(0.2, name=\"DROPOUT\")(x['pooled_output'])\n",
        "x = tf.keras.layers.Dense(num_class, activation='softmax', name=\"OUTPUT\")(x)\n",
        "model_classification = tf.keras.Model(i, x, name=\"USE_INTENT_CLASSIFICATION\")\n",
        "model_classification.load_weights(\"/content/Closed-Domain-Chatbot/weight/intent_classification_weight.hdf5\")\n",
        "\n",
        "#translator\n",
        "translator_th_en = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-th-en\")\n",
        "#slots labeling\n",
        "model_labeling = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
        "#sentiment analysis\n",
        "comment_sentiment = pipeline('sentiment-analysis', 'airesearch/wangchanberta-base-att-spm-uncased', revision = 'finetuned@wisesight_sentiment')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "W3VbIZtsdS_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title chatbot\n",
        "def get_answer(input_text):\n",
        "    ###########################################################\n",
        "    # text preparation\n",
        "    ###########################################################\n",
        "    clean_words_master = pd.read_excel('dataset/text_normalization.xlsx', sheet_name = 'clean_words')\n",
        "    th_stopwords = pd.read_excel('dataset/stopwords.xlsx', sheet_name = 'stop_words')\n",
        "    th_stopwords = th_stopwords['stop_words'].to_list()\n",
        "    txt_normalize = normalize(input_text)\n",
        "    for _,w in clean_words_master.iterrows():\n",
        "    \ttxt_normalize = txt_normalize.replace(w['original'],w['clean'])\n",
        "    txt_tokenize = subword_tokenize(txt_normalize, engine=\"wangchanberta\")\n",
        "    for i in txt_tokenize:\n",
        "      if (i.replace('▁','') in th_stopwords) & (len(i.strip())>0):\n",
        "        txt_rm_stopwords = txt_normalize.replace(i,'')\n",
        "    for _,w in clean_words_master.iterrows():\n",
        "    \ttxt_clean = txt_rm_stopwords.replace(w['original'],w['clean'])\n",
        "    ###########################################################\n",
        "    # intent classification\n",
        "    ###########################################################\n",
        "    question_txt = txt_clean\n",
        "    answer_text = []\n",
        "    overview_class = label_dict.get(np.argmax(model_classification.predict([question_txt])))\n",
        "    ###########################################################\n",
        "    # slots labeling for each class (sentiment analysis for comment class)\n",
        "    ###########################################################\n",
        "    ov_th = 0.4\n",
        "    if (overview_class == \"ask_for_info\") | (model_classification.predict([question_txt])[0][0] > ov_th):\n",
        "    \ttrans_to_en = translator_th_en(question_txt, src_lang='th', tgt_lang='en')\n",
        "    \tsequence_to_classify =  trans_to_en[0].get('translation_text')\n",
        "    \tshop_labels = ['size', 'cost', 'material', 'color','promotion', 'shop']\n",
        "    \tshop_prob_detail = model_labeling(sequence_to_classify, shop_labels, multi_label=True)\n",
        "    \tshop_prob_detail = pd.DataFrame(shop_prob_detail)[['labels','scores']]\n",
        "\n",
        "    \tth_1 = 0.6\n",
        "    \tif \"เสื้อ\" in question_txt:\n",
        "    \t  if ('เสื้อครอป' in question_txt) | ('ครึ่งตัว' in question_txt):\n",
        "    \t\t  answ = 'สินค้าเสื้อครอปครึ่งตัว '+product_detail('เสื้อครอปครึ่งตัว',shop_prob_detail, th_1)\n",
        "    \t\t  answer_text.append(answ)\n",
        "    \t  if 'เสื้อคลุม' in question_txt:\n",
        "    \t\t  answ = 'สินค้าเสื้อคลุม '+product_detail('เสื้อคลุม', shop_prob_detail, th_1)\n",
        "    \t\t  answer_text.append(answ)\n",
        "    \t  if (('เสื้อยืด' in question_txt) | ('เสื้อยืด' in question_txt)) & ('ครึ่งตัว' not in question_txt) & ('เสื้อครอป' not in question_txt) & ('เสื้อคลุม' not in question_txt):\n",
        "    \t\t  answ = 'สินค้าเสื้อยืดเต็มตัว '+product_detail('เสื้อยืดเต็มตัว', shop_prob_detail, th_1)\n",
        "    \t\t  answer_text.append(answ)\n",
        "    \tif \"กางเกง\" in question_txt:\n",
        "    \t  if 'กางเกงขายาว' in question_txt:\n",
        "    \t\t  answ = 'สินค้ากางเกงขายาว '+product_detail('กางเกงขายาว', shop_prob_detail, th_1)\n",
        "    \t\t  answer_text.append(answ)\n",
        "    \t  if 'กางเกงขาสั้น' in question_txt:\n",
        "    \t\t  answ = 'สินค้ากางเกงขาสั้น '+product_detail('กางเกงขาสั้น', shop_prob_detail, th_1)\n",
        "    \t\t  answer_text.append(answ)\n",
        "    \tif 'กระโปรง' in question_txt:\n",
        "    \t  if 'กระโปรงพลีท' in question_txt:\n",
        "    \t\t  answ = 'สินค้ากระโปรงพลีท '+product_detail('กระโปรงพลีท', shop_prob_detail, th_1)\n",
        "    \t\t  answer_text.append(answ)\n",
        "    \t  if 'กระโปรงทรงเอ' in question_txt:\n",
        "    \t\t  answ = 'สินค้ากระโปรงทรงเอ '+product_detail('กระโปรงทรงเอ', shop_prob_detail, th_1)\n",
        "    \t\t  answer_text.append(answ)\n",
        "\n",
        "    \tif shop_prob_detail.loc[shop_prob_detail['labels']=='shop','scores'].item() >= th_1:\n",
        "    \t  answ = \"\"\"THE CLOTHSET ร้านขายเสื้อผ้าสำหรับสตรี\n",
        "ทางร้านมีขายทั้งเสื้อครอปตัวสั้น, เสื้อยืด, เสื้อคลุม, กางเกงขายาว, กางเกงขาสั้น, กระโปรงพลีท, กระโปรงทรงเอ\n",
        "หากสนใจสินค้าตัวไหนสามารถสอบถามได้เลยนะคะ\"\"\"\n",
        "    \t  answer_text.append(answ)\n",
        "    \telse:\n",
        "    \t  if len(answer_text)==0: #chatGPT\n",
        "    \t\t  answ = open_domain(question_txt)\n",
        "    \t\t  answer_text.append(answ)\n",
        "\n",
        "    elif (overview_class == \"shop_open\") | (model_classification.predict([question_txt])[0][4] > ov_th):\n",
        "    \ttrans_to_en = translator_th_en(question_txt, src_lang='th', tgt_lang='en')\n",
        "    \tsequence_to_classify =  trans_to_en[0].get('translation_text')\n",
        "    \tshop_labels = ['when', 'where', 'contact', 'shop']\n",
        "    \tshop_prob = model_labeling(sequence_to_classify, shop_labels, multi_label=True)\n",
        "    \tshop_prob = pd.DataFrame(shop_prob)[['labels','scores']]\n",
        "\n",
        "    \tshop_th = 0.6\n",
        "    \tif shop_prob.loc[shop_prob['labels']=='when','scores'].item() >= shop_th:\n",
        "    \t  answ = shop_information[0]\n",
        "    \t  answer_text.append(answ)\n",
        "    \tif shop_prob.loc[shop_prob['labels']=='contact','scores'].item() >= shop_th:\n",
        "    \t  answ = shop_information[1]\n",
        "    \t  answer_text.append(answ)\n",
        "    \tif shop_prob.loc[shop_prob['labels']=='where','scores'].item() >= shop_th:\n",
        "    \t  answ = shop_information[2]\n",
        "    \t  answer_text.append(answ)\n",
        "    \tif shop_prob.loc[shop_prob['labels']=='shop','scores'].item() >= shop_th:\n",
        "    \t  answ = \"\"\"THE CLOTHSET ร้านขายเสื้อผ้าสำหรับสตรี\n",
        "ทางร้านมีขายทั้งเสื้อครอปตัวสั้น, เสื้อยืด, เสื้อคลุม, กางเกงขายาว, กางเกงขาสั้น, กระโปรงพลีท, กระโปรงทรงเอ\n",
        "หากสนใจสินค้าตัวไหนสามารถสอบถามได้เลยนะคะ\"\"\"\n",
        "    \t  answer_text.append(answ)\n",
        "    \telse:\n",
        "    \t  if len(answer_text)==0: #chatGPT\n",
        "    \t\t  answ = open_domain(question_txt)\n",
        "    \t\t  answer_text.append(answ)\n",
        "\n",
        "    elif (overview_class == \"comment\") | (model_classification.predict([question_txt])[0][1] > ov_th):\n",
        "      cm_class = comment_sentiment(question_txt)[0].get('label')\n",
        "      if cm_class == 'neg':\n",
        "    \t  answ = 'ทางร้านขออภัยเป็นอย่างยิ่งในความผิดพลาดที่เกิดขึ้น ทางร้านจะพยายามทำการแก้ไขอย่างเร็วที่สุดค่ะ'\n",
        "    \t  answer_text.append(answ)\n",
        "      elif cm_class == 'pos':\n",
        "      \tansw = 'ขอขอบคุณคุณลูกค้ามากนะคะ ที่ให้ความไว้วางใจ ทางร้านยินดีให้บริการเสมอค่ะ'\n",
        "      \tanswer_text.append(answ)\n",
        "      else:\n",
        "      \tif len(answer_text)==0: #chatGPT\n",
        "      \t\tansw = open_domain(question_txt)\n",
        "\n",
        "    elif (overview_class == \"greeting\") | (model_classification.predict([question_txt])[0][2] > ov_th):\n",
        "      trans_to_en = translator_th_en(question_txt, src_lang='th', tgt_lang='en')\n",
        "      sequence_to_classify =  trans_to_en[0].get('translation_text')\n",
        "      shop_labels = ['hello','thank']\n",
        "      shop_prob_greeting = model_labeling(sequence_to_classify, shop_labels, multi_label=True)\n",
        "      shop_prob_greeting = pd.DataFrame(shop_prob_greeting)[['labels','scores']]\n",
        "\n",
        "      th_2 = 0.6\n",
        "      if shop_prob_greeting.loc[shop_prob_greeting['labels']=='hello','scores'].item() >= th_2:\n",
        "      \tansw = 'สวัสดีค่ะ THE CLOTHSET ยินดีรับใช้บริการค่ะ หากสนใจสินค้าตัวไหนสามารถสอบถามได้เลยนะคะ'\n",
        "      \tanswer_text.append(answ)\n",
        "      elif shop_prob_greeting.loc[shop_prob_greeting['labels']=='thank','scores'].item() >= th_2:\n",
        "      \tansw = 'ขอขอบคุณคุณลูกค้ามากนะคะ ที่ให้ความไว้วางใจ ซื้อสินค้ากับทางร้าน THE CLOTHSET ยินดีรับใช้บริการค่ะ'\n",
        "      \tanswer_text.append(answ)\n",
        "      else:\n",
        "      \tansw = 'THE CLOTHSET ยินดีรับใช้บริการค่ะ'\n",
        "      \tanswer_text.append(answ)\n",
        "    elif (overview_class == \"order\") | (model_classification.predict([question_txt])[0][3] > ov_th):\n",
        "      trans_to_en = translator_th_en(question_txt, src_lang='th', tgt_lang='en')\n",
        "      sequence_to_classify =  trans_to_en[0].get('translation_text')\n",
        "      shop_labels = ['interest','not interest','refund']\n",
        "      shop_prob_order = model_labeling(sequence_to_classify, shop_labels, multi_label=True)\n",
        "      shop_prob_order = pd.DataFrame(shop_prob_order)[['labels','scores']]\n",
        "\n",
        "      th_3 = 0.6\n",
        "      if shop_prob_order.loc[shop_prob_order['labels']=='interest','scores'].item() >= th_3:\n",
        "      \tansw = \"\"\"ขอบพระคุณมาก ๆ ค่ะคุณลูกค้า ที่ให้ความไว้วางใจ ซื้อสินค้ากับทางร้าน THE CLOTHSET\n",
        "ทางรบกวนขอชื่อที่อยู่และเบอร์ติดต่อ\n",
        "โดยหากโอนเงินแล้วรบกวนแนบรูปสลิปด้วยนะคะ\n",
        "โอนธนาคาร xxx เลขบัญชี 1234-567-890\"\"\"\n",
        "      \tanswer_text.append(answ)\n",
        "      elif shop_prob_order.loc[shop_prob_order['labels']=='not interest','scores'].item() >= th_3:\n",
        "      \tansw = 'รับทราบค่ะ หากมีข้อสงสัยเพิ่มเติม THE CLOTHSET ยินดีรับใช้บริการค่ะ'\n",
        "      \tanswer_text.append(answ)\n",
        "      elif shop_prob_order.loc[shop_prob_order['labels']=='refund','scores'].item() >= th_3:\n",
        "      \tansw = 'ขออภัยเป็นอย่างสูงค่ะคุณลูกค้า เดี๋ยวทางร้านจะรีบประสานงานให้นะคะ'\n",
        "      \tanswer_text.append(answ)\n",
        "      else:\n",
        "      \tansw = 'ขออภัยค่ะ เดี๋ยวทางร้านจะรีบประสานงานให้นะคะ'\n",
        "      \tanswer_text.append(answ)\n",
        "    ######################################\n",
        "    answer_clean = '\\n'.join(answer_text)\n",
        "    return answer_clean"
      ],
      "metadata": {
        "cellView": "form",
        "id": "eCHJ5MXUuBRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chatbot result"
      ],
      "metadata": {
        "id": "svsWV1kIyW3S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**example result**"
      ],
      "metadata": {
        "id": "8fK__VlV2oY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_answer('ร้านเปิดตอนหนัยบ้างอ่าคะ พอดีอยากทราบเบอร์ติดต่ออ่ะค่ะๆ'))"
      ],
      "metadata": {
        "id": "5rKbPetoya4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**connect line**"
      ],
      "metadata": {
        "id": "roUEKCxo2Bz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "channel_access_token = '<channel_access_token_here>'\n",
        "channel_secret = '<channel_secret_here>'\n",
        "ngrok_authen_token = '<ngrok token>'"
      ],
      "metadata": {
        "id": "G3n5R7ez6J-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "port_no = 5000\n",
        "\n",
        "#Flask\n",
        "app = Flask(__name__)\n",
        "ngrok.set_auth_token(ngrok_authen_token)\n",
        "public_url =  ngrok.connect(port_no).public_url\n",
        "\n",
        "line_bot_api = LineBotApi(channel_access_token)\n",
        "handler = WebhookHandler(channel_secret)\n",
        "\n",
        "@app.route(\"/callback\", methods=['POST'])\n",
        "def callback():\n",
        "\n",
        "    req = request.get_json(silent=True, force=True)\n",
        "\n",
        "    input_msg = req['events'][0]['message']['text']\n",
        "    reply_token = req['events'][0]['replyToken']\n",
        "    user_id = req['events'][0]['source']['userId']\n",
        "\n",
        "    ans_text = get_answer(input_msg)\n",
        "\n",
        "    output_msg = TextSendMessage(text=ans_text)\n",
        "    line_bot_api.push_message(user_id, output_msg)\n",
        "\n",
        "#Flask\n",
        "if __name__ == '__main__':\n",
        "    public_url_s = public_url.replace(\"http://\",\"https://\")\n",
        "    print(f\"To acces the Gloable link please click {public_url_s}/callback\")\n",
        "    print(\"Starting app on port %d\" % port_no)\n",
        "    app.run(debug=False, port=port_no, threaded=True)"
      ],
      "metadata": {
        "id": "bV6pUioE2I9C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}